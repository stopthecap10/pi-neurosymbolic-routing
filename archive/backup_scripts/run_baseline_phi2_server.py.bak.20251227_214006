import argparse
import csv
import json
import statistics
import time
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

import requests

DEFAULT_SERVER_URL = "http://127.0.0.1:8080/completion"
DEFAULT_TIMEOUT_S = 20.0

DEFAULT_YESNO_GRAMMAR = "grammars/grammar_yesno_only.gbnf"
DEFAULT_NUM_GRAMMAR = "grammars/grammar_int_only.gbnf"

DEFAULT_N_PRED_NUM = 32
DEFAULT_N_PRED_LOG = 8

def read_text(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def extract_answer(category: str, content: str) -> str:
    # Keep it simple: strip whitespace.
    # Grammar should make this already clean (int-only or Yes/No only).
    return (content or "").strip()

def is_correct(expected: str, got: str) -> int:
    return 1 if (expected or "").strip() == (got or "").strip() else 0

def pick_n_predict(category: str, n_pred_num: int, n_pred_log: int) -> int:
    return n_pred_log if category.upper() == "LOG" else n_pred_num

def pick_grammar(category: str, num_grammar: str, yesno_grammar: str) -> str:
    return yesno_grammar if category.upper() == "LOG" else num_grammar

def post_completion(
    server_url: str,
    prompt: str,
    n_predict: int,
    temperature: float,
    grammar: Optional[str],
    timeout_s: float,
) -> Tuple[str, Optional[float]]:
    """
    Returns:
      (text, compute_latency_s_if_available)
    """
    payload: Dict[str, Any] = {
        "prompt": prompt,
        "n_predict": int(n_predict),
        "temperature": float(temperature),
    }
    # Always set grammar explicitly for safety.
    # For no-grammar, pass "".
    if grammar is None:
        payload["grammar"] = ""
    else:
        payload["grammar"] = grammar

    r = requests.post(server_url, json=payload, timeout=timeout_s)
    r.raise_for_status()
    data = r.json()

    # llama.cpp server usually returns "content"
    text = data.get("content", "")
    # Try to parse compute time if present
    compute_s = None
    timings = data.get("timings")
    if isinstance(timings, dict):
        # predicted_ms is typical
        pm = timings.get("predicted_ms")
        if isinstance(pm, (int, float)):
            compute_s = float(pm) / 1000.0
    return text, compute_s

@dataclass
class TrialRow:
    id: str
    category: str
    variant: str
    expected_answer: str
    trial_index: int
    final_output: str
    correct: int
    latency_wall_s: float
    latency_compute_s: Optional[float]

@dataclass
class SummaryRow:
    id: str
    category: str
    variant: str
    expected_answer: str
    final_output: str
    correct: int
    latency_wall_median_s: float
    latency_compute_median_s: Optional[float]

def run_variant(
    rows: List[Dict[str, str]],
    variant: str,
    mode: str,
    server_url: str,
    timeout_s: float,
    repeats: int,
    warmup_per_prompt: int,
    n_pred_num: int,
    n_pred_log: int,
    num_grammar_text: str,
    yesno_grammar_text: str,
) -> Tuple[List[SummaryRow], List[TrialRow]]:
    summaries: List[SummaryRow] = []
    trials: List[TrialRow] = []

    for row in rows:
        pid = row["id"].strip()
        cat = row["category"].strip()
        prompt = row["prompt"]
        expected = row["expected_answer"].strip()

        # Warmups (not recorded)
        for _ in range(max(0, warmup_per_prompt)):
            try:
                n_predict = pick_n_predict(cat, n_pred_num, n_pred_log)
                g = pick_grammar(cat, num_grammar_text, yesno_grammar_text) if mode == "grammar" else None
                post_completion(server_url, prompt, n_predict, 0.0, g, timeout_s)
            except Exception:
                pass

        wall_times: List[float] = []
        compute_times: List[float] = []
        outputs: List[str] = []

        for t in range(repeats):
            start = time.time()
            out_text = ""
            compute_s = None
            ok = 0
            try:
                n_predict = pick_n_predict(cat, n_pred_num, n_pred_log)
                g = pick_grammar(cat, num_grammar_text, yesno_grammar_text) if mode == "grammar" else None
                text, compute_s = post_completion(server_url, prompt, n_predict, 0.0, g, timeout_s)
                out_text = extract_answer(cat, text)
                ok = is_correct(expected, out_text)
            except Exception:
                # Timeout / HTTP error counts as failure, logged with empty output and ok=0
                out_text = ""
                ok = 0
                compute_s = None

            wall = time.time() - start
            wall_times.append(wall)
            if compute_s is not None:
                compute_times.append(compute_s)
            outputs.append(out_text)

            trials.append(TrialRow(
                id=pid,
                category=cat,
                variant=variant,
                expected_answer=expected,
                trial_index=t + 1,
                final_output=out_text,
                correct=ok,
                latency_wall_s=wall,
                latency_compute_s=compute_s,
            ))

        # Median latencies
        wall_med = float(statistics.median(wall_times))
        compute_med = float(statistics.median(compute_times)) if compute_times else None

        # Choose the output corresponding to the median wall latency (stable + interpretable)
        med_idx = sorted(range(len(wall_times)), key=lambda i: wall_times[i])[len(wall_times)//2]
        final_out = outputs[med_idx]
        final_ok = is_correct(expected, final_out)

        summaries.append(SummaryRow(
            id=pid,
            category=cat,
            variant=variant,
            expected_answer=expected,
            final_output=final_out,
            correct=final_ok,
            latency_wall_median_s=wall_med,
            latency_compute_median_s=compute_med,
        ))

    return summaries, trials

def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument("--csv", required=True, help="Input prompts CSV")
    ap.add_argument("--out", required=True, help="Summary output CSV path")
    ap.add_argument("--trials_out", default=None, help="Trials output CSV path (optional)")
    ap.add_argument("--mode", choices=["grammar", "nogrammar", "both"], default="grammar",
                    help="Which baseline(s) to run")
    ap.add_argument("--server_url", default=DEFAULT_SERVER_URL)
    ap.add_argument("--timeout_s", type=float, default=DEFAULT_TIMEOUT_S)
    ap.add_argument("--repeats", type=int, default=3)
    ap.add_argument("--warmup_per_prompt", type=int, default=0)
    ap.add_argument("--n_pred_num", type=int, default=DEFAULT_N_PRED_NUM)
    ap.add_argument("--n_pred_log", type=int, default=DEFAULT_N_PRED_LOG)
    ap.add_argument("--num_grammar_file", default=DEFAULT_NUM_GRAMMAR)
    ap.add_argument("--yesno_grammar_file", default=DEFAULT_YESNO_GRAMMAR)
    args = ap.parse_args()

    # Load prompts AFTER parsing args
    with open(args.csv, newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        rows = list(reader)

    # Load grammars once
    num_grammar = read_text(args.num_grammar_file)
    yesno_grammar = read_text(args.yesno_grammar_file)

    all_summaries: List[SummaryRow] = []
    all_trials: List[TrialRow] = []

    def add(mode: str, variant: str) -> None:
        s, t = run_variant(
            rows=rows,
            variant=variant,
            mode=mode,
            server_url=args.server_url,
            timeout_s=args.timeout_s,
            repeats=args.repeats,
            warmup_per_prompt=args.warmup_per_prompt,
            n_pred_num=args.n_pred_num,
            n_pred_log=args.n_pred_log,
            num_grammar_text=num_grammar,
            yesno_grammar_text=yesno_grammar,
        )
        all_summaries.extend(s)
        all_trials.extend(t)

    if args.mode in ("grammar", "both"):
        add("grammar", "phi2_server_grammar")
    if args.mode in ("nogrammar", "both"):
        add("nogrammar", "phi2_server_nogrammar")

    # Write summary
    with open(args.out, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["id","category","variant","expected_answer","final_output","correct",
                    "latency_wall_median_s","latency_compute_median_s"])
        for r in all_summaries:
            w.writerow([r.id, r.category, r.variant, r.expected_answer, r.final_output, r.correct,
                        f"{r.latency_wall_median_s:.6f}",
                        (f"{r.latency_compute_median_s:.6f}" if r.latency_compute_median_s is not None else "")])

    # Write trials if requested
    if args.trials_out:
        with open(args.trials_out, "w", newline="", encoding="utf-8") as f:
            w = csv.writer(f)
            w.writerow(["id","category","variant","expected_answer","trial_index","final_output","correct",
                        "latency_wall_s","latency_compute_s"])
            for r in all_trials:
                w.writerow([r.id, r.category, r.variant, r.expected_answer, r.trial_index, r.final_output, r.correct,
                            f"{r.latency_wall_s:.6f}",
                            (f"{r.latency_compute_s:.6f}" if r.latency_compute_s is not None else "")])

if __name__ == "__main__":
    main()
