Model: Phi-2 Q4_K_M (GGUF)
Engine: llama.cpp (llama-completion)
Threads: 4
Context length: 512
Max tokens: 32
Temperature: 0
Grammar: NONE (LLM-only baseline)
Timeout: 20 seconds
Prompt template: "Answer with only the final number. {QUESTION}"
Hardware: Raspberry Pi (edge device)
